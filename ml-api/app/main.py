from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import os
from dotenv import load_dotenv
from app.model import SkinDiseaseModel
from app.utils import save_upload_file, cleanup_file
import logging
from pydantic import BaseModel
import google.generativeai as genai
import asyncio

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# C·∫•u h√¨nh log
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Skin Disease Classification API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 1. C·∫§U H√åNH GEMINI (CHATBOT) ---
GENAI_KEY = os.getenv("GEMINI_API_KEY")
model_gemini = None

if GENAI_KEY:
    try:
        genai.configure(api_key=GENAI_KEY)
        # S·ª≠ d·ª•ng model flash (Chu·∫©n m·ªõi nh·∫•t c·ªßa Google)
        model_gemini = genai.GenerativeModel('gemini-flash-latest')
        logger.info("‚úÖ C·∫•u h√¨nh Gemini th√†nh c√¥ng (Model:gemini-flash-latest)")
    except Exception as e:
        logger.error(f"‚ö†Ô∏è L·ªói c·∫•u h√¨nh Gemini: {e}")
else:
    logger.warning("‚ö†Ô∏è Ch∆∞a c√≥ GEMINI_API_KEY trong docker-compose.yml")

# --- 2. C·∫§U H√åNH MODEL PH√ÇN T√çCH ·∫¢NH ---
model = None

@app.on_event("startup")
async def startup_event():
    """T·∫£i model AI khi server kh·ªüi ƒë·ªông"""

    # [DEBUG] Ki·ªÉm tra xem t√†i kho·∫£n Key c·ªßa b·∫°n c√≥ nh·ªØng model n√†o
    if GENAI_KEY:
        logger.info("üîç ƒêang ki·ªÉm tra danh s√°ch Model Google kh·∫£ d·ª•ng...")
        try:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    logger.info(f"   ---> T√¨m th·∫•y model: {m.name}")
        except Exception as e:
            logger.error(f"‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c danh s√°ch model: {e}")

    global model
    logger.info("‚è≥ ƒêang t·∫£i model ph√¢n t√≠ch ·∫£nh (M·∫•t kho·∫£ng 1-2 ph√∫t)...")
    try:
        # Ch·∫°y trong thread ri√™ng ƒë·ªÉ kh√¥ng ch·∫∑n server
        model = SkinDiseaseModel()
        logger.info("‚úÖ Model ph√¢n t√≠ch ·∫£nh ƒë√£ t·∫£i xong!")
    except Exception as e:
        logger.error(f"‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c model ·∫£nh: {str(e)}")

@app.get("/")
async def root():
    return {"status": "running", "ai_model_loaded": model is not None}

# --- API PH√ÇN T√çCH ·∫¢NH ---
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    if model is None:
        raise HTTPException(status_code=503, detail="AI ƒëang kh·ªüi ƒë·ªông, vui l√≤ng ƒë·ª£i 30 gi√¢y r·ªìi th·ª≠ l·∫°i.")

    temp_file_path = None
    try:
        temp_file_path = await save_upload_file(file)
        result = model.predict(temp_file_path)

        return JSONResponse(content={
            "success": True,
            "predicted_class": result['predicted_class'],
            "predicted_class_vi": result.get('predicted_class_vi', result['predicted_class']),
            "confidence": result['confidence'],
            "all_predictions": result['all_predictions']
        })
    except Exception as e:
        logger.error(f"L·ªói khi ph√¢n t√≠ch: {str(e)}")
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}")
    finally:
        if temp_file_path:
            cleanup_file(temp_file_path)

# --- API CHATBOT ---
class ChatRequest(BaseModel):
    message: str
    disease_context: str = None

@app.post("/chat")
async def chat_with_doctor(request: ChatRequest):
    if not model_gemini:
        raise HTTPException(status_code=503, detail="Ch∆∞a c·∫•u h√¨nh API Key Gemini ho·∫∑c Key b·ªã l·ªói.")

    try:
        context = ""
        if request.disease_context:
            context = f"Th√¥ng tin b·ªánh nh√¢n: V·ª´a ƒë∆∞·ª£c ch·∫©n ƒëo√°n '{request.disease_context}'. "

        prompt = f"""
        B·∫°n l√† DermAssist, tr·ª£ l√Ω y t·∫ø chuy√™n v·ªÅ da li·ªÖu.
        Nhi·ªám v·ª•: Tr·∫£ l·ªùi ng·∫Øn g·ªçn, tr·∫•n an ng∆∞·ªùi b·ªánh.
        {context}
        C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: "{request.message}"
        """

        response = model_gemini.generate_content(prompt)

        if response.text:
            return {"reply": response.text}
        else:
            return {"reply": "Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi. B·∫°n h·ªèi l·∫°i nh√©?"}

    except Exception as e:
        logger.error(f"L·ªói Chatbot: {e}")
        # N·∫øu l·ªói 404, log s·∫Ω hi·ªán ra ƒë·ªÉ ta bi·∫øt ƒë∆∞·ªùng s·ª≠a
        raise HTTPException(status_code=500, detail="B√°c sƒ© ·∫£o ƒëang b·∫≠n, th·ª≠ l·∫°i sau.")

if __name__ == "__main__":
    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=True)
